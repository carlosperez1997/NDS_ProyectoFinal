{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "colab": {
      "name": "eda_commercial_activity.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAZtcEutwskJ"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBJx4dGgwskS"
      },
      "source": [
        "def df_description(df):\n",
        "    \"\"\" df_description: returns a briefly description of the variables in a dataframe\n",
        "        inputs: \n",
        "            - df : dataframe\n",
        "        outputs:\n",
        "            - None (prints information on the terminal)\n",
        "    \"\"\"\n",
        "    display(df.head())\n",
        "\n",
        "    print('\\n\\n Dataframe info: \\n')\n",
        "    display(df.info())\n",
        "\n",
        "    print('\\n\\n Dataframe description: ')\n",
        "    display(df.describe(include='all'))  \n",
        "    return None\n",
        "\n",
        "def df_nulls(df):\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8AMnqWuwskU"
      },
      "source": [
        "## Commercial actitivity\n",
        "\n",
        "El dataset 'commercial activity' tiene las siguientes variables:\n",
        "- **pk_cid** (int64)\n",
        "\n",
        "    Identificador de cliente\n",
        "- **pk_partition** (object : date)\n",
        "\n",
        "    Fecha de ingesta de los datos. Existen 17 particiones o históricos.\n",
        "- **entry_date** (object : date)\n",
        "\n",
        "    Fecha en la que realizó la primera contratación a través de easyMoney\n",
        "- **entry_channel** (object : category)\n",
        "\n",
        "    Canal de captación del cliente. Existen 69 canales diferentes. \n",
        "- **active_customer** (float64 : bool)\n",
        "\n",
        "    Indicador de actividad del cliente en nuestra aplicación\n",
        "- **segment** (object : category)\n",
        "\n",
        "    Segmento comercial del cliente. Existen 3 segmentos: '01 - TOP', '02 - PARTICULARES', '03 - UNIVERSITARIO'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V70M9DKkwskU"
      },
      "source": [
        "commercial_activity_all = pd.read_csv('./data/commercial_activity_df.csv', index_col=0)\n",
        "df_description(commercial_activity_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idm0iVdKwskW"
      },
      "source": [
        "partitions = commercial_activity_all['pk_partition'].unique()\n",
        "partitions = sorted(partitions)\n",
        "display(partitions)\n",
        "\n",
        "print(\"Se tienen {} particiones\".format(len(partitions)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-_f6v1LwskX"
      },
      "source": [
        "partitions_valuecounts = commercial_activity_all['pk_partition'].value_counts()\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.barh(partitions_valuecounts.index, partitions_valuecounts[:])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-xzJgYKwskX"
      },
      "source": [
        "Como se indica en el correo de John, el dataset incluye 17 particiones o históricos (*pk_partition*). Como se puede observar el número de filas o *entries* en cada partición va aumentado con el transcurso de los meses. Se espera que la última partición contenga todos los datos de las particiones anteriores (esta suposición se comprobará), y para el EDA (Exploratory Data Analysis) se trabajará con esta partición, dado que el dataset entero contiene datos duplicados.\n",
        "\n",
        "Como se puede observar en las siguientes tablas la última partición tiene 442.995 *entries* o filas. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmme5XuswskY"
      },
      "source": [
        "commercial_activity_df = commercial_activity_all[  commercial_activity_all['pk_partition'] == partitions[-1]]\n",
        "df_description(commercial_activity_df)\n",
        "del commercial_activity_all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhTMJNXcwskY"
      },
      "source": [
        "En las siguientes figuras, se comprueban los valores nulos en el dataframe *commercial_activity_df*. Se puede observar en la última figura que los valores nulos que aparecen en *entry_channel* y *segment* ocurren en la mayoría de casos en ambos campos a la vez. \n",
        "\n",
        "Los valores nulos, 4616 en el peor de los casos sobre 442995, lo que corresponde alrededor del 1% de las filas del dataframe, por lo que descartar estas filas tampoco supondrá un cambio muy drástico en los futuros resultados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FM1hm7sSwskZ"
      },
      "source": [
        "# Obtener los NaNs en cada columna\n",
        "commercial_activity_df.isna().sum().plot( kind=\"bar\" )\n",
        "plt.show()\n",
        "display(commercial_activity_df.isna().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQIik-oGwskZ"
      },
      "source": [
        "import missingno as msno \n",
        "  \n",
        "# Visualize missing values as a matrix \n",
        "msno.matrix(commercial_activity_df) \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApIzuF-Uwska"
      },
      "source": [
        "### Preprocessing\n",
        "\n",
        "En esta parte se realizará una limpieza de los datos. Los pasos a seguir son los siguientes:\n",
        "\n",
        "La información se conserva entre las particiones, pero puede hacer algunas discrepancias entre las particiones, y algunos datos pueden haber sido alterados. \n",
        "- Pasar la variable *entry_channel* y *segment* a category\n",
        "    - Mirar que category es más predominante\n",
        "- Pasar las variables *pk_partition* y *entry_date* a 'date'\n",
        "    - Añadir variables de año, mes, dia, dia de la semana, año-mes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd7Tl3bbwska"
      },
      "source": [
        "#### Comprobar si existen discrepancias entre particiones\n",
        "\n",
        "En este apartado se comprobará que no existe duplicidad de las filas entre las particiones. El proceso para comprobar si existen duplicados se puede comprobar si:\n",
        "- Si tan sólo aparece una fila para cada combincación de pk_cid, entry_date, entry_channel\n",
        "\n",
        "https://appdividend.com/2020/03/07/python-pandas-find-duplicate-rows-in-dataframe-based-on-all-or-selected-columns/#:~:text=If%20you%20want%20to%20find,duplicated()%20function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xI43BA5Awskb"
      },
      "source": [
        "first_partition = commercial_activity_df[(commercial_activity_df['pk_partition']=='2018-01-28')]\n",
        "\n",
        "print(first_partition.shape)\n",
        "\n",
        "second_partition = commercial_activity_df[(commercial_activity_df['pk_partition']=='2018-02-28')] \n",
        "print(second_partition.shape)\n",
        "\n",
        "first_two_partitions = pd.merge(first_partition, second_partition, on=['pk_cid', 'entry_date', 'entry_channel', 'segment'], how='outer', suffixes=['_1','_2'])\n",
        "\n",
        "print(first_two_partitions.shape)\n",
        "\n",
        "new_clients = first_two_partitions[ first_two_partitions['pk_partition_1'].isna() ] \n",
        "first_two_partitions = first_two_partitions.drop(index=new_clients.index)\n",
        "\n",
        "print(first_two_partitions.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfYobAf6wskc"
      },
      "source": [
        "#### Limpieza de categorías \n",
        "\n",
        "En este paso se codificarán las variables *entry_channel* y *segment* como category. Para ello primero se codifican los NaNs como 'Sin asignar'.\n",
        "\n",
        "Pasar de object a category se consigue reducir el tamaño en la memoria del dataframe y simplificar el dataset en caso de que se desee realizar un one-line-enconding, por ejemplo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SPHMpPUwskd"
      },
      "source": [
        "commercial_activity_df['entry_channel'] = commercial_activity_df['entry_channel'].fillna('Sin Asignar')\n",
        "commercial_activity_df['segment'] = commercial_activity_df['segment'].fillna('Sin Asignar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJ8f75Vewskd"
      },
      "source": [
        "# Obtener categorias entry_channel \n",
        "entry_channel_cats = commercial_activity_df['entry_channel'].unique()\n",
        "display(entry_channel_cats)\n",
        "\n",
        "print(\"Numero de categorias 'entry_channel': {}\".format(entry_channel_cats.shape[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDdFtQfewske"
      },
      "source": [
        "# top 10 entry_channel más usados\n",
        "entry_channel_value_counts = commercial_activity_df['entry_channel'].value_counts()\n",
        "\n",
        "entry_channel_value_counts = entry_channel_value_counts.sort_values(ascending=False).head(10)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=[10,4])\n",
        "ax.barh(entry_channel_value_counts.index, entry_channel_value_counts[:])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MODY6xGKwskf"
      },
      "source": [
        "# Obtener categorias segment \n",
        "segment_cats = commercial_activity_df['segment'].unique()\n",
        "display(segment_cats)\n",
        "\n",
        "print(\"Numero de categorias 'segment': {}\".format(segment_cats.shape[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syJ975Epwskg"
      },
      "source": [
        "# Segments más usados\n",
        "\n",
        "segment_value_counts = commercial_activity_df['segment'].value_counts()\n",
        "\n",
        "segment_value_counts = segment_value_counts.sort_values(ascending=False)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=[10,4])\n",
        "ax.bar(segment_value_counts.index, segment_value_counts[:])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgzPtBduwskh"
      },
      "source": [
        "Se puede observar como hay categorias NaN. De todas maneras convertimos la columna a category. Más adelante, realizaremos una limpieza y decidiremos qué hacer con los NaNs en la columna de *segment*. \n",
        "\n",
        "En la siguiente figura se puede ver el numero de cuentas que corresponden a cada una de las categorias. Antes se ha asignado la categoria NaN como 'Sin Asignar' para que así aparezca en la figura."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnCJH7LOwskj"
      },
      "source": [
        "**¿Qué realizamos con las categorias sin asignar?**\n",
        "\n",
        "#commercial_activity_df['entry_channel'] = commercial_activity_df['entry_channel'].astype('category')\n",
        "#assert commercial_activity_df['entry_channel'].dtype == 'category'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC7L127owskk"
      },
      "source": [
        "# Si menospreciamos 'Sin Asignar' tanto en segment como en 'entry_channel'\n",
        "print('Dataframe con los NaNs:')\n",
        "print(commercial_activity_df.shape)\n",
        "\n",
        "print('Dataframe sin los NaNs de entry_channel:')\n",
        "new_commercial_activity_df = commercial_activity_df[(commercial_activity_df['entry_channel'] != 'Sin Asignar')]\n",
        "print(new_commercial_activity_df.shape)\n",
        "\n",
        "print('Dataframe sin los NaNs de segment:')\n",
        "new_commercial_activity_df = commercial_activity_df[(commercial_activity_df['segment'] != 'Sin Asignar')]\n",
        "print(new_commercial_activity_df.shape)\n",
        "\n",
        "print('Dataframe sin los NaNs de ambos:')\n",
        "new_commercial_activity_df = commercial_activity_df[ (commercial_activity_df['entry_channel'] != 'Sin Asignar') & (commercial_activity_df['segment'] != 'Sin Asignar') ]\n",
        "print(new_commercial_activity_df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIKZQ0E_wskk"
      },
      "source": [
        "Deshacerse de las filas en las que *entry_channel* o *segment* es nulo representa tan sólo el 1% de todas las filas. Por lo que se considera, que es un mal menor y deshacerse de estas filas es un paso correcto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dOVYYMywskl"
      },
      "source": [
        "commercial_activity_df.shape[0] - new_commercial_activity_df.shape[0]\n",
        "(commercial_activity_df.shape[0]-new_commercial_activity_df.shape[0])/commercial_activity_df.shape[0]*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8eU9_M7wskl"
      },
      "source": [
        "commercial_activity_df = commercial_activity_df[ (commercial_activity_df['entry_channel'] != 'Sin Asignar') & (commercial_activity_df['segment'] != 'Sin Asignar') ]\n",
        "print(commercial_activity_df.isna().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQ5QBbHNwskm"
      },
      "source": [
        "Convertir las variables *entry_channel* y *segment* a category."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8qluakQwskm"
      },
      "source": [
        "commercial_activity_df['entry_channel'] = commercial_activity_df['entry_channel'].astype('category')\n",
        "commercial_activity_df['segment'] = commercial_activity_df['segment'].astype('category')\n",
        "\n",
        "assert commercial_activity_df['entry_channel'].dtype == 'category'\n",
        "assert commercial_activity_df['segment'].dtype == 'category'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgsXAFCWwskn"
      },
      "source": [
        "De la variable de *active_customers* (variable boolean) se puede obtener los usuarios activos. Pero, ¿existe una fila para cada usuario, o un usuario puede aparecer en varios filas? Si la segunda opción es la verdadera para poder visualizar los usuarios activos (más recientes) habría que agrupar por usuario y quedarse con el valor de fila que tenga la fecha más reciente a la actual. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quBQqkmDwsko"
      },
      "source": [
        "active_customers = commercial_activity_df['active_customer'].value_counts()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=[6,4])\n",
        "ax.bar(['non-active customers','active customers'], active_customers[:] )\n",
        "ax.set_title('Usuarios activos y no activos')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uE-EW5Wgwsko"
      },
      "source": [
        "### Preparación de las variables fecha \n",
        "- Pasar las variables pk_partition y entry_date a 'date'\n",
        "    - Añadir variables de año, mes, dia, dia de la semana, año-mes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZT_hoTLwskp"
      },
      "source": [
        "from datetime import datetime as dt\n",
        "# 2015-02-29 = esta fecha no existe!\n",
        "\n",
        "wrong_dates = {'2015-02-29': '2015-02-28', '2019-02-29':'2019-02-28'}\n",
        "commercial_activity_df['entry_date'] = commercial_activity_df['entry_date'].replace(wrong_dates)\n",
        "\n",
        "commercial_activity_df['entry_date'] = pd.to_datetime(commercial_activity_df['entry_date'], format='%Y-%m-%d')\n",
        "\n",
        "commercial_activity_df['pk_partition'] = commercial_activity_df['pk_partition'].replace(wrong_dates)\n",
        "\n",
        "commercial_activity_df['pk_partition'] = pd.to_datetime(commercial_activity_df['pk_partition'], format='%Y-%m-%d')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Neid6se_wskp"
      },
      "source": [
        "commercial_activity_df['pk_partition_year'] = commercial_activity_df.pk_partition.dt.year\n",
        "commercial_activity_df['pk_partition_month'] = commercial_activity_df.pk_partition.dt.month\n",
        "commercial_activity_df['pk_partition_day'] = commercial_activity_df.pk_partition.dt.day\n",
        "commercial_activity_df['pk_partition_dayofweek'] = commercial_activity_df.pk_partition.dt.dayofweek\n",
        "commercial_activity_df['pk_partition_year_month'] = commercial_activity_df.pk_partition.dt.strftime('%Y-%m')\n",
        "\n",
        "commercial_activity_df['entry_date_year'] = commercial_activity_df.entry_date.dt.year\n",
        "commercial_activity_df['entry_date_month'] = commercial_activity_df.entry_date.dt.month\n",
        "commercial_activity_df['entry_date_day'] = commercial_activity_df.entry_date.dt.day\n",
        "commercial_activity_df['entry_date_dayofweek'] = commercial_activity_df.entry_date.dt.dayofweek\n",
        "commercial_activity_df['entry_date_year_month'] = commercial_activity_df.entry_date.dt.strftime('%Y-%m')\n",
        "\n",
        "#df['order_purchase_date'] = df.order_purchase_timestamp.dt.date\n",
        "#df['order_purchase_year'] = df.order_purchase_timestamp.apply(lambda x: x.year)\n",
        "#df['order_purchase_month'] = df.order_purchase_timestamp.apply(lambda x: x.month)\n",
        "#df['order_purchase_dayofweek'] = df.order_purchase_timestamp.apply(lambda x: x.dayofweek)\n",
        "#df['order_purchase_hour'] = df.order_purchase_timestamp.apply(lambda x: x.hour)\n",
        "#df['order_purchase_day'] = df['order_purchase_dayofweek'].map({0:'Mon',1:'Tue',2:'Wed',3:'Thu',4:'Fri',5:'Sat',6:'Sun'})\n",
        "#df['order_purchase_mon'] = df.order_purchase_timestamp.apply(lambda x: x.month).map({1:'Jan',2:'Feb',3:'Mar',4:'Apr',5:'May',6:'Jun',7:'Jul',8:'Aug',9:'Sep',10:'Oct',11:'Nov',12:'Dec'})\n",
        "#df['order_count']=1\n",
        "#df['year_month'] = df['order_purchase_timestamp'].dt.strftime('%Y-%m')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}